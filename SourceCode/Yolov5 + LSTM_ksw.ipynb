{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import random  \n",
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image, clear_output\n",
    "from torch.cuda import memory_allocated, empty_cache\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Yolov5 torch_ë²„ì „ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kimsungwook/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ğŸš€ 2024-4-17 Python-3.11.7 torch-2.2.2 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# torch_ver Yolov5\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s',\n",
    "                            device='cuda:0' if torch.cuda.is_available() else 'cpu')  # ì˜ˆì¸¡ ëª¨ë¸\n",
    "yolo_model.classes = [0]  # ì˜ˆì¸¡ í´ë˜ìŠ¤ (0 : ì‚¬ëŒ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë°ì´í„° ì „ì²˜ë¦¬ ë° ì„¸ë¶€ ì¡°ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pose : Only Body\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 40\n",
    "EPOCH = 700\n",
    "NUM_LAYERS = 1      # LSTM model: num_layers\n",
    "start_dot = 11      # mp.solutions.pose ì‹œì‘ í¬ì¸íŠ¸ (0: ì–¼êµ´ë¶€í„° ë°œëª©ê¹Œì§€, 11: ì–´ê¹¨ë¶€í„° ë°œëª©ê¹Œì§€)\n",
    "n_CONFIDENCE = 0.3    # MediaPipe Min Detectin confidence check\n",
    "y_CONFIDENCE = 0.3    # Yolv5 Min Detectin confidence check\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "attention_dot = [n for n in range(start_dot, 29)]\n",
    "\n",
    "# ë¼ì¸ ê·¸ë¦¬ê¸°\n",
    "if start_dot == 11:\n",
    "    \"\"\"ëª¸ ë¶€ë¶„ë§Œ\"\"\"\n",
    "    draw_line = [[11, 13], [13, 15], [15, 21], [15, 19], [15, 17], [17, 19], \\\n",
    "                [12, 14], [14, 16], [16, 22], [16, 20], [16, 18], [18, 20], \\\n",
    "                [23, 25], [25, 27], [24, 26], [26, 28], [11, 12], [11, 23], \\\n",
    "                [23, 24], [12, 24]]\n",
    "    print('Pose : Only Body')\n",
    "\n",
    "else:\n",
    "    \"\"\"ì–¼êµ´ í¬í•¨\"\"\"\n",
    "    draw_line = [[11, 13], [13, 15], [15, 21], [15, 19], [15, 17], [17, 19], \\\n",
    "                [12, 14], [14, 16], [16, 22], [16, 20], [16, 18], [18, 20], \\\n",
    "                [23, 25], [25, 27], [24, 26], [26, 28], [11, 12], [11, 23], \\\n",
    "                [23, 24], [12, 24], [9, 10], [0, 5], [0, 2], [5, 8], [2, 7]]\n",
    "    print('Pose : Face + Body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yolov4 ë°”ìš´ë”© box ì•ˆì—ì„œ media pipe ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜\n",
    "\n",
    "def get_skeleton(video_path, attention_dot, draw_line):\n",
    "    frame_length = 30 # LSTM ëª¨ë¸ì— ë„£ì„ frame ìˆ˜\n",
    "\n",
    "    xy_list_list, xy_list_list_flip = [], []\n",
    "    cv2.destroyAllWindows()\n",
    "    pose = mp_pose.Pose(static_image_mode = True, model_complexity = 1, \\\n",
    "                        enable_segmentation = False, min_detection_confidence = n_CONFIDENCE)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if cap.isOpened():\n",
    "\n",
    "        while True:\n",
    "            ret, img = cap.read()\n",
    "\n",
    "            if ret == True:\n",
    "\n",
    "                \"\"\" Yolo ë°”ìš´ë”© ë°•ìŠ¤ ë° ì¢Œí‘œ ì¶”ì¶œ\"\"\"\n",
    "                img = cv2.resize(img, (640, 640))\n",
    "                res = yolo_model(img)\n",
    "                res_refine = res.pandas().xyxy[0].values\n",
    "                nms_human = len(res_refine)\n",
    "                if nms_human > 0:\n",
    "                    for bbox in res_refine:\n",
    "                        \"\"\"ë°”ìš´ë”© ë°•ìŠ¤ ìƒí•˜ì¢Œìš° í¬ê¸° ì¡°ì ˆ\"\"\"\n",
    "                        xx1, yy1, xx2, yy2 = int(bbox[0])-10, int(bbox[1]), int(bbox[2])+10, int(bbox[3])\n",
    "                        if xx1 < 0:\n",
    "                            xx1 = 0\n",
    "                        elif xx2 > 639:\n",
    "                            xx2 = 639\n",
    "                        if yy1 < 0:\n",
    "                            yy1 = 0\n",
    "                        elif yy2 > 639:\n",
    "                            yy2 = 639\n",
    "\n",
    "                        start_point = (xx1, yy1)\n",
    "                        end_point = (xx2, yy2)\n",
    "\n",
    "                        \"\"\" Yolov5 ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì•ˆì—ì„œ mediapipe Pose ì¶”ì¶œ\"\"\"\n",
    "                        if bbox[4] > y_CONFIDENCE: # bbox[4] : confidence ë°ì´í„°\n",
    "                            # img = cv2.rectangle(img, start_point, end_point, (0, 0, 255), 2) # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° : ë°ì´í„° ì¶”ì¶œ í™•ì¸ìš©\n",
    "                            c_img = img[yy1:yy2, xx1:xx2] # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ\n",
    "                            results = pose.process(cv2.cvtColor(c_img, cv2.COLOR_BGR2RGB)) # Yolov5 ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì•ˆì—ì„œ 'mp_pose' ì¢Œí‘œ\n",
    "\n",
    "                            if not results.pose_landmarks: continue\n",
    "                            idx = 0\n",
    "                            draw_line_dic = {}\n",
    "                            xy_list, xy_list_flip = [], []\n",
    "                            # 33 ë°˜ë³µë¬¸ ì§„í–‰ : 33ê°œ ì¤‘ 18ê°œì˜ dot\n",
    "                            for x_and_y in results.pose_landmarks.landmark:\n",
    "                                if idx in attention_dot:\n",
    "                                    xy_list.append(x_and_y.x)\n",
    "                                    xy_list.append(x_and_y.y)\n",
    "                                    xy_list_flip.append(1 - x_and_y.x)\n",
    "                                    xy_list_flip.append(x_and_y.y)\n",
    "\n",
    "                                    x, y = int(x_and_y.x*(xx2-xx1)), int(x_and_y.y*(yy2-yy1))\n",
    "                                    draw_line_dic[idx] = [x, y]\n",
    "                                idx += 1\n",
    "\n",
    "                            if len(xy_list) != len(attention_dot) * 2:\n",
    "                                print('Error : attention_dot ë°ì´í„° ì˜¤ë¥˜')\n",
    "\n",
    "                            xy_list_list.append(xy_list)\n",
    "                            xy_list_list_flip.append(xy_list_flip)\n",
    "\n",
    "                            \"\"\"mediapipe line ê·¸ë¦¬ê¸° ë¶€ë¶„ : ë°ì´í„° ì¶”ì¶œ(dot) í™•ì¸ìš©\"\"\"\n",
    "                            # for line in draw_line:\n",
    "                            #     x1, y1 = draw_line_dic[line[0]][0], draw_line_dic[line[0]][1]\n",
    "                            #     x2, y2 = draw_line_dic[line[1]][0], draw_line_dic[line[1]][1]\n",
    "                            #     c_img = cv2.line(c_img, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "                            # # cv2.imshow('Landmark Image', img)\n",
    "                            # cv2_imshow(img)\n",
    "                            # cv2.waitKey(1)\n",
    "\n",
    "            elif ret == False: break\n",
    "\n",
    "\n",
    "        # ë¶€ì¡±í•œ í”„ë ˆì„ ìˆ˜ ë§ì¶”ê¸°\n",
    "        if len(xy_list_list_flip) < 15:\n",
    "            return False, False\n",
    "        elif len(xy_list_list_flip) < frame_length:\n",
    "            f_ln = frame_length - len(xy_list_list_flip)\n",
    "            for _ in range(f_ln):\n",
    "                xy_list_list.append(xy_list_list[-1])\n",
    "                xy_list_list_flip.append(xy_list_list_flip[-1])\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    return xy_list_list, xy_list_list_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../dataset_aihub/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = '../../dataset_aihub/' # dataset ê²½ë¡œ\n",
    "video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abnormal_á„€á…¡á†¼á„ƒá…©á†¼á„‹á…®á†¨', 'normal_á„€á…¡á†¼á„ƒá…©á†¼á„‹á…®á†¨', '.DS_Store', 'abnormal_á„€á…µá†·á„‰á…¥á†¼á„‹á…®á†¨', 'normal_á„€á…µá†·á„‰á…¥á†¼á„‹á…®á†¨', 'normal_á„€á…¡á†¼á„†á…µá†«á„Œá…µ', 'abnormal_á„€á…µá†·á„‰á…¥á†¼á„‹á…®á†¨.pickle', 'normal_á„€á…¡á†¼á„†á…µá†«á„Œá…µ.pickle', 'abnormal_á„€á…¡á†¼á„†á…µá†«á„Œá…µ', 'normal_á„€á…¡á†¼á„ƒá…©á†¼á„‹á…®á†¨.pickle', 'normal_á„€á…µá†·á„‰á…¥á†¼á„‹á…®á†¨.pickle', 'abnormal_á„€á…¡á†¼á„†á…µá†«á„Œá…µ.pickle']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(video_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ìƒ ë°ì´í„°ì—ì„œ mp pose landmark dot ë°ì´í„° ì¶”ì¶œ ë¶€ë¶„\n",
    "# raw_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fold in os.listdir(video_path):\n",
    "#    for video_name in os.listdir(video_path + '/' + fold):\n",
    "#        if int(video_name.split('_')[2][:2]) >= 30: # video name ì°¸ì¡°\n",
    "#            if video_name.split('_')[1] == 'normal': label = 0\n",
    "#            else: label = 1\n",
    "#            skel_data_n, skel_data_f = get_skeleton('{}/{}'.format(video_path + '/' + fold, video_name), attention_dot, draw_line)\n",
    "#            if skel_data_n != False:\n",
    "#                seq_list_n = skel_data_n[:30]\n",
    "#                seq_list_f = skel_data_f[:30]\n",
    "#                raw_data.append({'key':label, 'value':seq_list_n})\n",
    "#                raw_data.append({'key':label, 'value':seq_list_f})\n",
    "# random.shuffle(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 'abnormal_á„€á…µá†·á„‰á…¥á†¼á„‹á…®á†¨'\n",
    "raw_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713925506.950551 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "I0000 00:00:1713925511.373322 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925514.912259 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925518.465557 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925522.637580 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925526.109154 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925529.713653 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925533.949761 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925537.484679 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925542.705914 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925547.131919 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925551.414632 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925555.597268 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925560.720610 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925565.870275 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925569.527002 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925573.185431 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925578.293196 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925581.366903 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925586.310618 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925589.848099 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925593.431222 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925597.010069 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925602.492777 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925606.667472 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925610.834648 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925614.656572 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925619.452762 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925625.144330 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925629.627796 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925634.507692 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925641.619345 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925652.324088 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713925659.898431 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925667.040029 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925673.892237 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925683.256754 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925691.548729 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925699.659104 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925707.416840 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925718.530044 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925723.749148 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925730.664721 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925736.334567 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925744.698111 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925751.364103 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925759.183410 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925767.105436 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925772.424203 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713925779.299708 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925788.510169 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925794.229668 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925802.508413 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925808.982230 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925814.817535 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925820.852718 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925828.649119 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925835.817864 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925843.491659 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925849.292086 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925857.511664 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925864.412607 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925871.344407 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925878.041367 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925883.811235 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925892.092883 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713925899.606046 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925906.262769 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925917.100696 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925922.363149 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925929.084725 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925936.589684 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925944.399504 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713925951.494336 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n"
     ]
    }
   ],
   "source": [
    "for video_name in os.listdir(video_path + '/' + fold):\n",
    "    if int(video_name.split('_')[2][:2]) >= 30: # video name ì°¸ì¡°\n",
    "        if video_name.split('_')[1] == 'normal': label = 0\n",
    "        else: label = 1\n",
    "        skel_data_n, skel_data_f = get_skeleton('{}/{}'.format(video_path + '/' + fold, video_name), attention_dot, draw_line)\n",
    "        if skel_data_n != False:\n",
    "            seq_list_n = skel_data_n[:30]\n",
    "            seq_list_f = skel_data_f[:30]\n",
    "            raw_data.append({'key':label, 'value':seq_list_n})\n",
    "            raw_data.append({'key':label, 'value':seq_list_f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../dataset_aihub/abnormal_á„€á…µá†·á„‰á…¥á†¼á„‹á…®á†¨.pickle\n"
     ]
    }
   ],
   "source": [
    "filename = video_path + fold + '.pickle'\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(raw_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 'normal_á„€á…µá†·á„‰á…¥á†¼á„‹á…®á†¨'\n",
    "raw_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713923467.303726 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923472.308378 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923475.638770 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923478.803307 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923482.759004 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923487.288174 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923490.541359 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923494.509557 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923498.627024 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923502.357009 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923506.563674 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923511.406712 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923515.347779 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713923520.691875 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923524.207789 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923528.233902 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923531.968615 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923536.938438 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923540.980089 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923545.140296 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923549.739591 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923553.507858 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923557.891020 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923562.104338 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923567.079354 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923571.579189 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923577.704923 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923582.088042 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923587.447530 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923594.693370 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713923599.996015 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923606.121909 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923613.720444 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923620.619171 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923628.876491 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923635.020109 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923644.930563 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923652.359343 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923658.473437 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923667.012678 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923673.017907 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923678.854370 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923686.334733 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923693.655102 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923699.693022 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923705.823675 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923712.523804 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713923718.828797 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923723.064631 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923728.983807 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923733.912241 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923738.666899 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923743.885250 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923749.246802 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923755.612519 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923761.272472 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923767.147829 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923774.587663 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923780.332998 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923786.247202 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923791.261117 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923799.371226 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923806.562856 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713923811.276714 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923815.495489 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923822.548533 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923828.907405 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923833.476732 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923839.265316 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923845.498376 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923854.339594 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923859.658668 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923865.087410 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713923869.890024 2117701 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n"
     ]
    }
   ],
   "source": [
    "for video_name in os.listdir(video_path + '/' + fold):\n",
    "    if int(video_name.split('_')[2][:2]) >= 30: # video name ì°¸ì¡°\n",
    "        if video_name.split('_')[1] == 'normal': label = 0\n",
    "        else: label = 1\n",
    "        skel_data_n, skel_data_f = get_skeleton('{}/{}'.format(video_path + '/' + fold, video_name), attention_dot, draw_line)\n",
    "        if skel_data_n != False:\n",
    "            seq_list_n = skel_data_n[:30]\n",
    "            seq_list_f = skel_data_f[:30]\n",
    "            raw_data.append({'key':label, 'value':seq_list_n})\n",
    "            raw_data.append({'key':label, 'value':seq_list_f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../dataset_aihub/normal_á„€á…µá†·á„‰á…¥á†¼á„‹á…®á†¨.pickle\n"
     ]
    }
   ],
   "source": [
    "filename = video_path + fold + '.pickle'\n",
    "print(filename)\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(raw_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 'normal_á„€á…¡á†¼á„†á…µá†«á„Œá…µ'\n",
    "raw_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713926004.397779 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926008.272915 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926011.759046 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926015.482457 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926019.153446 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926023.855109 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926026.943515 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926030.758632 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926034.335859 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713926037.962627 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926042.368035 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926047.899196 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926052.716701 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926057.230190 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926062.277451 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926068.665618 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926075.379329 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926081.780968 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926088.474370 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926095.348077 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926102.397928 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926108.679812 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926115.698309 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926122.433335 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926128.835415 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713926136.023887 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926142.560822 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926149.612347 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926156.022480 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926163.299996 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926169.560926 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926175.793766 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926181.850747 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926188.021821 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926194.008601 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926199.769154 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926206.031532 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926212.568275 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926219.187892 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926225.468546 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926231.929946 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926238.312049 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713926246.537993 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926252.129672 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926260.595342 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926266.307696 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926272.428371 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926279.260490 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926286.093448 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926292.801277 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926299.442175 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926306.457415 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926312.767041 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926319.022784 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926325.240277 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926331.546522 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926337.583314 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n"
     ]
    }
   ],
   "source": [
    "for video_name in os.listdir(video_path + '/' + fold):\n",
    "    if int(video_name.split('_')[2][:2]) >= 30: # video name ì°¸ì¡°\n",
    "        if video_name.split('_')[1] == 'normal': label = 0\n",
    "        else: label = 1\n",
    "        skel_data_n, skel_data_f = get_skeleton('{}/{}'.format(video_path + '/' + fold, video_name), attention_dot, draw_line)\n",
    "        if skel_data_n != False:\n",
    "            seq_list_n = skel_data_n[:30]\n",
    "            seq_list_f = skel_data_f[:30]\n",
    "            raw_data.append({'key':label, 'value':seq_list_n})\n",
    "            raw_data.append({'key':label, 'value':seq_list_f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../dataset_aihub/normal_á„€á…¡á†¼á„†á…µá†«á„Œá…µ.pickle\n"
     ]
    }
   ],
   "source": [
    "filename = video_path + fold + '.pickle'\n",
    "print(filename)\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(raw_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 'abnormal_á„€á…¡á†¼á„†á…µá†«á„Œá…µ'\n",
    "raw_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713926420.539487 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926424.109958 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713926427.611580 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926431.016424 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926434.419624 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926437.867506 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926441.324933 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926444.885199 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926448.132161 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926451.639177 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926455.226392 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926459.603685 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926463.150704 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926466.756428 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926470.702122 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926474.081338 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926478.069593 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926482.020930 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713926485.976853 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926491.195071 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926495.724335 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926500.332566 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926505.264266 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926510.705772 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926519.287175 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926526.863637 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926534.509887 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926542.644850 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926550.677405 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926558.429940 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926566.471219 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926573.879980 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926580.860914 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926587.826679 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926594.220598 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713926600.310012 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926606.595391 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926612.705000 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926619.018583 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926625.067798 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926632.543356 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926637.058526 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926642.988949 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926648.262973 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926654.118545 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926659.789494 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926665.435938 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926670.957793 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926676.164548 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926681.786255 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926687.414997 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926693.034892 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713926697.844261 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926703.570304 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926709.251557 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926715.297556 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926721.096027 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713926727.063726 2150928 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n"
     ]
    }
   ],
   "source": [
    "for video_name in os.listdir(video_path + '/' + fold):\n",
    "    if int(video_name.split('_')[2][:2]) >= 30: # video name ì°¸ì¡°\n",
    "        if video_name.split('_')[1] == 'normal': label = 0\n",
    "        else: label = 1\n",
    "        skel_data_n, skel_data_f = get_skeleton('{}/{}'.format(video_path + '/' + fold, video_name), attention_dot, draw_line)\n",
    "        if skel_data_n != False:\n",
    "            seq_list_n = skel_data_n[:30]\n",
    "            seq_list_f = skel_data_f[:30]\n",
    "            raw_data.append({'key':label, 'value':seq_list_n})\n",
    "            raw_data.append({'key':label, 'value':seq_list_f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../dataset_aihub/abnormal_á„€á…¡á†¼á„†á…µá†«á„Œá…µ.pickle\n"
     ]
    }
   ],
   "source": [
    "filename = video_path + fold + '.pickle'\n",
    "print(filename)\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(raw_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 'normal_á„€á…¡á†¼á„ƒá…©á†¼á„‹á…®á†¨'\n",
    "raw_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713927269.082791 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927273.199822 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927276.546000 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927279.488086 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927282.855879 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927286.539801 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927290.546852 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927294.461070 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927297.843639 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927301.121262 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927304.621479 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927308.327751 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927311.617652 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927315.657688 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927318.973497 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927322.529768 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927326.373111 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927330.153234 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713927333.140051 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927336.624235 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927340.188912 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927343.707912 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927347.247719 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927351.356302 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927354.936938 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927357.985852 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927361.609096 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927365.957622 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927369.395625 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927374.152252 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927378.286099 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927381.828722 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927386.400484 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927391.103511 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713927396.906497 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927403.210219 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927408.851376 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927415.183508 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927421.914443 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927427.916382 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927434.661636 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927441.046736 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927447.410403 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927452.794960 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927458.815143 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927464.602331 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927472.259087 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927477.827733 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927483.997734 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927490.009881 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927496.080053 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713927500.938381 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927507.444887 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927512.080033 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927517.124039 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927522.102536 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927527.781466 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927532.392534 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927537.392529 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927542.146686 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927547.747440 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927552.855879 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927558.069118 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927562.622092 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927569.755909 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927575.389415 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927580.719847 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927588.124896 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713927592.365856 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927599.583026 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927605.058877 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927611.424799 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927618.105340 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927622.444865 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927629.448366 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927634.996478 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927639.768510 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927644.995665 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927650.915203 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927656.283939 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927662.654974 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927667.368242 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927672.394827 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927678.171850 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713927683.594174 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927690.138478 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927695.410540 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927699.742974 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927705.569770 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713927710.612177 2165579 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n"
     ]
    }
   ],
   "source": [
    "for video_name in os.listdir(video_path + '/' + fold):\n",
    "    if int(video_name.split('_')[2][:2]) >= 30: # video name ì°¸ì¡°\n",
    "        if video_name.split('_')[1] == 'normal': label = 0\n",
    "        else: label = 1\n",
    "        skel_data_n, skel_data_f = get_skeleton('{}/{}'.format(video_path + '/' + fold, video_name), attention_dot, draw_line)\n",
    "        if skel_data_n != False:\n",
    "            seq_list_n = skel_data_n[:30]\n",
    "            seq_list_f = skel_data_f[:30]\n",
    "            raw_data.append({'key':label, 'value':seq_list_n})\n",
    "            raw_data.append({'key':label, 'value':seq_list_f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../dataset_aihub/normal_á„€á…¡á†¼á„ƒá…©á†¼á„‹á…®á†¨.pickle\n"
     ]
    }
   ],
   "source": [
    "filename = video_path + fold + '.pickle'\n",
    "print(filename)\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(raw_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 'abnormal_á„€á…¡á†¼á„ƒá…©á†¼á„‹á…®á†¨'\n",
    "raw_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713929276.202884   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "I0000 00:00:1713929280.671034   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929284.409014   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929287.912746   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929291.369299   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929294.468276   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929298.430020   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929301.655776   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929304.937523   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929308.360752   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929312.504835   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929315.786567   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929319.127392   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929323.324603   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929327.562673   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929330.984365   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929335.259237   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929338.753208   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929342.348068   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929345.965383   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929350.402869   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929354.054655   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929358.215930   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929362.852412   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929367.585084   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929371.892864   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929375.693759   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929379.471954   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929383.942955   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929388.835483   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929395.939285   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929401.794016   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929408.908945   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713929416.436155   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929424.217113   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929432.988502   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929442.478696   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929450.465835   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929457.854891   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929466.716717   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929472.587404   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929480.785405   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929487.192144   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929493.705523   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929500.312106   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929506.473602   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929513.598652   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929519.130441   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929524.888943   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713929531.061364   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929537.211753   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929543.403405   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929549.565758   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929557.961091   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929565.529679   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929571.448623   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929578.561952   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929584.221436   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929590.052560   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929596.168433   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929602.548448   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929608.957121   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929615.022219   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929622.395979   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929628.378940   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929634.431635   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713929640.511013   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929647.793546   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929653.675952   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929659.707849   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929665.629939   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929671.714822   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929677.012813   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929684.922388   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929692.133493   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929698.499843   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929705.584611   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929711.557661   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929717.913853   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929725.027238   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929732.476452   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929739.246708   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929746.214552   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "Context leak detected, msgtracer returned -1\n",
      "I0000 00:00:1713929753.276184   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929759.814001   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929766.589657   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929772.962889   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929780.916347   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929787.788920   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n",
      "I0000 00:00:1713929793.519704   12242 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M2\n"
     ]
    }
   ],
   "source": [
    "for video_name in os.listdir(video_path + '/' + fold):\n",
    "    if int(video_name.split('_')[2][:2]) >= 30: # video name ì°¸ì¡°\n",
    "        if video_name.split('_')[1] == 'normal': label = 0\n",
    "        else: label = 1\n",
    "        skel_data_n, skel_data_f = get_skeleton('{}/{}'.format(video_path + '/' + fold, video_name), attention_dot, draw_line)\n",
    "        if skel_data_n != False:\n",
    "            seq_list_n = skel_data_n[:30]\n",
    "            seq_list_f = skel_data_f[:30]\n",
    "            raw_data.append({'key':label, 'value':seq_list_n})\n",
    "            raw_data.append({'key':label, 'value':seq_list_f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../dataset_aihub/abnormal_á„€á…¡á†¼á„ƒá…©á†¼á„‹á…®á†¨.pickle\n"
     ]
    }
   ],
   "source": [
    "filename = video_path + fold + '.pickle'\n",
    "print(filename)\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(raw_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "pickles = sorted(glob.glob('../../dataset_aihub/*.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../dataset_aihub/abnormal_á„€á…¡á†¼á„ƒá…©á†¼á„‹á…®á†¨.pickle', '../../dataset_aihub/abnormal_á„€á…¡á†¼á„†á…µá†«á„Œá…µ.pickle', '../../dataset_aihub/abnormal_á„€á…µá†·á„‰á…¥á†¼á„‹á…®á†¨.pickle', '../../dataset_aihub/normal_á„€á…¡á†¼á„ƒá…©á†¼á„‹á…®á†¨.pickle', '../../dataset_aihub/normal_á„€á…¡á†¼á„†á…µá†«á„Œá…µ.pickle', '../../dataset_aihub/normal_á„€á…µá†·á„‰á…¥á†¼á„‹á…®á†¨.pickle']\n"
     ]
    }
   ],
   "source": [
    "print(pickles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "for onepickle in pickles:\n",
    "    with open(onepickle, 'rb') as f:\n",
    "        raw_data += pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../dataset_aihub/abnormal_á„€á…¡á†¼á„ƒá…©á†¼á„‹á…®á†¨.pickle 170\n",
      "../../dataset_aihub/abnormal_á„€á…¡á†¼á„†á…µá†«á„Œá…µ.pickle 362\n",
      "../../dataset_aihub/abnormal_á„€á…µá†·á„‰á…¥á†¼á„‹á…®á†¨.pickle 142\n",
      "../../dataset_aihub/normal_á„€á…¡á†¼á„ƒá…©á†¼á„‹á…®á†¨.pickle 164\n",
      "../../dataset_aihub/normal_á„€á…¡á†¼á„†á…µá†«á„Œá…µ.pickle 250\n",
      "../../dataset_aihub/normal_á„€á…µá†·á„‰á…¥á†¼á„‹á…®á†¨.pickle 296\n"
     ]
    }
   ],
   "source": [
    "for onepickle in pickles:\n",
    "    with open(onepickle, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        print(onepickle,len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal data: 14 | abnormal data: 16\n"
     ]
    }
   ],
   "source": [
    "# dataset ê¸¸ì´ ì¶œë ¥\n",
    "\n",
    "nd = 0\n",
    "ad = 0\n",
    "for i in range(len(raw_data)):\n",
    "    if raw_data[i]['key'] == 0:\n",
    "        nd += 1\n",
    "    else:\n",
    "        ad += 1\n",
    "print('normal data:', nd, '| abnormal data:', ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ëª¨ë¸ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, seq_list):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for dic in seq_list :\n",
    "            self.y.append(dic['key'])\n",
    "            self.X.append(dic['value'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24, 3, 3\n"
     ]
    }
   ],
   "source": [
    "split_ratio = [0.8, 0.1, 0.1]\n",
    "train_len = int(len(raw_data) * split_ratio[0])\n",
    "val_len = int(len(raw_data) * split_ratio[1])\n",
    "test_len = len(raw_data) - train_len - val_len\n",
    "\n",
    "print('{}, {}, {}'.format(train_len, val_len, test_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(raw_data)\n",
    "train_data, valid_data, test_data = random_split(train_dataset, [train_len, val_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "class skeleton_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(skeleton_LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=len(attention_dot) * 2, hidden_size=128, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=128, hidden_size=256, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=256, hidden_size=512, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.lstm4 = nn.LSTM(input_size=512, hidden_size=256, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.lstm5 = nn.LSTM(input_size=256, hidden_size=128, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.lstm6 = nn.LSTM(input_size=128, hidden_size=64, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.lstm7 = nn.LSTM(input_size=64, hidden_size=32, num_layers=NUM_LAYERS, batch_first=True)\n",
    "        self.fc = nn.Linear(32,2)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x, _ = self.lstm5(x)\n",
    "        x, _ = self.lstm6(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, _ = self.lstm7(x)\n",
    "        x = self.fc(x[:,-1,:]) # x[ë°°ì¹˜ í¬ê¸°, ì‹œí€€ìŠ¤ ê¸¸ì´, ì€ë‹‰ ìƒíƒœ í¬ê¸°], [:, -1, :] -> ë§ˆì§€ë§‰ ì‹œê°„ ë‹¨ê³„ë§Œ ì„ íƒ\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "\n",
    "def init_model():\n",
    "    global net, loss_fn, optim\n",
    "    plt.rc('font', size = 10)\n",
    "    net = skeleton_LSTM().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "# epoch ì¹´ìš´í„° ì´ˆê¸°í™”\n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "\n",
    "# ëª¨ë“  Logë¥¼ ì´ˆê¸°í™”\n",
    "def init_log():\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    plt.rc('font', size = 10)\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    # Train Log ê¸°ë¡\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "\n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    # Validation Log ê¸°ë¡\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "\n",
    "def last(log_list):\n",
    "    # last ì•ˆì˜ ë§ˆì§€ë§‰ ìˆ«ìë¥¼ ë°˜í™˜(print_log í•¨ìˆ˜ì—ì„œ ì‚¬ìš©)\n",
    "    if len(log_list) > 0:\n",
    "        return log_list[len(log_list) - 1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def print_log():\n",
    "    # í•™ìŠµ ì¶”ì´ ì¶œë ¥ : ì†Œìˆ«ì  3ìë¦¬ê¹Œì§€\n",
    "    train_loss = round(float(last(tloss_log)), 3)\n",
    "    train_acc = round(float(last(tacc_log)), 3)\n",
    "    val_loss = round(float(last(vloss_log)), 3)\n",
    "    val_acc = round(float(last(vacc_log)), 3)\n",
    "    time_spent = round(float(last(time_log)), 3)\n",
    "\n",
    "    log_str = 'Epoch: {:3} | T_Loss {:5} | T_Acc {:5} | V_Loss {:5} | V_Acc {:5} | {:5}'.format(last(iter_log), train_loss, train_acc, val_loss, val_acc, time_spent)\n",
    "\n",
    "    log_stack.append(log_str)\n",
    "    \n",
    "    # í•™ìŠµ ì¶”ì´ ê·¸ë˜í”„ ì¶œë ¥\n",
    "    hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99)\n",
    "    hist_fig.patch.set_facecolor('white')\n",
    "\n",
    "    # Loss Line êµ¬ì„±\n",
    "    loss_t_line = plt.plot(iter_log, tloss_log, label='Train_Loss', color='red', marker='o')\n",
    "    loss_v_line = plt.plot(iter_log, vloss_log, label='Valid_Loss', color='blue', marker='s')\n",
    "    loss_axis.set_xlabel('epoch')\n",
    "    loss_axis.set_ylabel('loss')\n",
    "\n",
    "    # Acc, Line êµ¬ì„±\n",
    "    acc_axis = loss_axis.twinx()\n",
    "    acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train_Acc', color='red', marker='+')\n",
    "    acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid_Acc', color='blue', marker='x')\n",
    "    acc_axis.set_ylabel('accuracy')\n",
    "\n",
    "    # ê·¸ë˜í”„ ì¶œë ¥\n",
    "    hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line\n",
    "    loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines])\n",
    "    loss_axis.grid()\n",
    "    plt.title('Learning history until epoch {}'.format(last(iter_log)))\n",
    "    plt.draw()\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ ë¡œê·¸ ì¶œë ¥\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "    for idx in reversed(range(len(log_stack))):\n",
    "        print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_memory():\n",
    "    if device != 'cpu':\n",
    "        empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# í•™ìŠµ ì•Œê³ ë¦¬ì¦˜\n",
    "def epoch(data_loader, mode = 'train'):\n",
    "    global epoch_cnt\n",
    "\n",
    "    # ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "    iter_loss, iter_acc, last_grad_performed = [], [], False\n",
    "\n",
    "    # 1 iteration í•™ìŠµ ì•Œê³ ë¦¬ì¦˜(forë¬¸ì„ ë‚˜ì˜¤ë©´ 1 epoch ì™„ë£Œ)\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.type(torch.LongTensor).to(device)\n",
    "\n",
    "        # 1. Feed-forward\n",
    "        if mode == 'train':\n",
    "            net.train()\n",
    "        else:\n",
    "            # í•™ìŠµë•Œë§Œ ì“°ì´ëŠ” Dropout, Batch Mormalizationì„ ë¯¸ì‚¬ìš©\n",
    "            net.eval()\n",
    "\n",
    "        result = net(data) # 1 Batchì— ëŒ€í•œ ê²°ê³¼ê°€ ëª¨ë“  Classì— ëŒ€í•œ í™•ë¥ ê°’ìœ¼ë¡œ\n",
    "        _, out = torch.max(result, 1) # resultì—ì„œ ìµœëŒ€ í™•ë¥ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ class ë„ì¶œ( _ : ê°’ ë¶€ë¶„ì€ í•„ìš” ì—†ìŒ, out : index ì¤‘ ê°€ì¥ í° í•˜ë‚˜ì˜ ë°ì´í„°)\n",
    "\n",
    "        # 2. Loss ê³„ì‚°\n",
    "        loss = loss_fn(result, label) # GT ì™€ Label ë¹„êµí•˜ì—¬ Loss ì‚°ì •\n",
    "        iter_loss.append(loss.item()) # í•™ìŠµ ì¶”ì´ë¥¼ ìœ„í•˜ì—¬ Lossë¥¼ ê¸°ë¡\n",
    "\n",
    "        # 3. ì—­ì „íŒŒ í•™ìŠµ í›„ Gradient Descent\n",
    "        if mode == 'train':\n",
    "            optim.zero_grad() # ë¯¸ë¶„ì„ í†µí•´ ì–»ì€ ê¸°ìš¸ê¸°ë¥¼ ì´ˆê¸°í™” for ë‹¤ìŒ epoch\n",
    "            loss.backward() # ì—­ì „íŒŒ í•™ìŠµ\n",
    "            optim.step() # Gradient Descent ìˆ˜í–‰\n",
    "            last_grad_performed = True # forë¬¸ì„ ë‚˜ê°€ë©´ epoch ì¹´ìš´í„° += 1\n",
    "\n",
    "        # 4. ì •í™•ë„ ê³„ì‚°\n",
    "        acc_partial = (out == label).float().sum() # GT == Label ì¸ ê°œìˆ˜\n",
    "        acc_partial = acc_partial / len(label) # ( TP / (TP + TM)) í•´ì„œ ì •í™•ë„ ì‚°ì¶œ\n",
    "        iter_acc.append(acc_partial.item()) # í•™ìŠµ ì¶”ì´ë¥¼ ìœ„í•˜ì—¬ Acc. ê¸°ë¡\n",
    "\n",
    "    # ì—­ì „íŒŒ í•™ìŠµ í›„ Epoch ì¹´ìš´í„° += 1\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "\n",
    "    clear_memory()\n",
    "\n",
    "    # lossì™€ accì˜ í‰ê· ê°’ for í•™ìŠµì¶”ì´ ê·¸ë˜í”„, ëª¨ë“  GTì™€ Label ê°’ for ì»¨í“¨ì „ ë§¤íŠ¸ë¦­ìŠ¤\n",
    "    return np.average(iter_loss), np.average(iter_acc)\n",
    "\n",
    "def epoch_not_finished():\n",
    "    # ì—í­ì´ ëë‚¨ì„ ì•Œë¦¼\n",
    "    return epoch_cnt < maximum_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- í•™ìŠµ ì§„í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 700 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.511\n",
      "Epoch: 699 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.504\n",
      "Epoch: 698 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.507\n",
      "Epoch: 697 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.506\n",
      "Epoch: 696 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.501\n",
      "Epoch: 695 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 |   1.5\n",
      "Epoch: 694 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.495\n",
      "Epoch: 693 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.494\n",
      "Epoch: 692 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.491\n",
      "Epoch: 691 | T_Loss 0.694 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.489\n",
      "Epoch: 690 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.493\n",
      "Epoch: 689 | T_Loss 0.695 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.488\n",
      "Epoch: 688 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.488\n",
      "Epoch: 687 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.487\n",
      "Epoch: 686 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.484\n",
      "Epoch: 685 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.483\n",
      "Epoch: 684 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 |  1.48\n",
      "Epoch: 683 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.476\n",
      "Epoch: 682 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.474\n",
      "Epoch: 681 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.475\n",
      "Epoch: 680 | T_Loss 0.686 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.469\n",
      "Epoch: 679 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 |  1.47\n",
      "Epoch: 678 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.468\n",
      "Epoch: 677 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.468\n",
      "Epoch: 676 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.461\n",
      "Epoch: 675 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.461\n",
      "Epoch: 674 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.457\n",
      "Epoch: 673 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.454\n",
      "Epoch: 672 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.456\n",
      "Epoch: 671 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.451\n",
      "Epoch: 670 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.453\n",
      "Epoch: 669 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 |  1.45\n",
      "Epoch: 668 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.449\n",
      "Epoch: 667 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.445\n",
      "Epoch: 666 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.447\n",
      "Epoch: 665 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.442\n",
      "Epoch: 664 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.442\n",
      "Epoch: 663 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.441\n",
      "Epoch: 662 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.436\n",
      "Epoch: 661 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.437\n",
      "Epoch: 660 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.435\n",
      "Epoch: 659 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.431\n",
      "Epoch: 658 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.429\n",
      "Epoch: 657 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |  1.43\n",
      "Epoch: 656 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.425\n",
      "Epoch: 655 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.427\n",
      "Epoch: 654 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |  1.42\n",
      "Epoch: 653 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.422\n",
      "Epoch: 652 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.417\n",
      "Epoch: 651 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.418\n",
      "Epoch: 650 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.415\n",
      "Epoch: 649 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.414\n",
      "Epoch: 648 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.413\n",
      "Epoch: 647 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.406\n",
      "Epoch: 646 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 |  1.41\n",
      "Epoch: 645 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.407\n",
      "Epoch: 644 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.406\n",
      "Epoch: 643 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.402\n",
      "Epoch: 642 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 |   1.4\n",
      "Epoch: 641 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 1.401\n",
      "Epoch: 640 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 1.401\n",
      "Epoch: 639 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 1.396\n",
      "Epoch: 638 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 1.392\n",
      "Epoch: 637 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 1.389\n",
      "Epoch: 636 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 1.389\n",
      "Epoch: 635 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 |  1.39\n",
      "Epoch: 634 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 1.386\n",
      "Epoch: 633 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 1.384\n",
      "Epoch: 632 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.383\n",
      "Epoch: 631 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.382\n",
      "Epoch: 630 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.378\n",
      "Epoch: 629 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.376\n",
      "Epoch: 628 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.375\n",
      "Epoch: 627 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.372\n",
      "Epoch: 626 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 |  1.37\n",
      "Epoch: 625 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 |  1.37\n",
      "Epoch: 624 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.368\n",
      "Epoch: 623 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.368\n",
      "Epoch: 622 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.366\n",
      "Epoch: 621 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.363\n",
      "Epoch: 620 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.361\n",
      "Epoch: 619 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.358\n",
      "Epoch: 618 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.359\n",
      "Epoch: 617 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.356\n",
      "Epoch: 616 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.352\n",
      "Epoch: 615 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.352\n",
      "Epoch: 614 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.349\n",
      "Epoch: 613 | T_Loss 0.694 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.349\n",
      "Epoch: 612 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.345\n",
      "Epoch: 611 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.343\n",
      "Epoch: 610 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.346\n",
      "Epoch: 609 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.339\n",
      "Epoch: 608 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 |  1.34\n",
      "Epoch: 607 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.336\n",
      "Epoch: 606 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.332\n",
      "Epoch: 605 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.332\n",
      "Epoch: 604 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.328\n",
      "Epoch: 603 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.326\n",
      "Epoch: 602 | T_Loss 0.694 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.327\n",
      "Epoch: 601 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.324\n",
      "Epoch: 600 | T_Loss 0.694 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.324\n",
      "Epoch: 599 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.321\n",
      "Epoch: 598 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 |  1.32\n",
      "Epoch: 597 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.315\n",
      "Epoch: 596 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.316\n",
      "Epoch: 595 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.314\n",
      "Epoch: 594 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.316\n",
      "Epoch: 593 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.311\n",
      "Epoch: 592 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.309\n",
      "Epoch: 591 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.305\n",
      "Epoch: 590 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.305\n",
      "Epoch: 589 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.304\n",
      "Epoch: 588 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.302\n",
      "Epoch: 587 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.301\n",
      "Epoch: 586 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.298\n",
      "Epoch: 585 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.298\n",
      "Epoch: 584 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.292\n",
      "Epoch: 583 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.294\n",
      "Epoch: 582 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.288\n",
      "Epoch: 581 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 |  1.29\n",
      "Epoch: 580 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.287\n",
      "Epoch: 579 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.286\n",
      "Epoch: 578 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.282\n",
      "Epoch: 577 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.281\n",
      "Epoch: 576 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.279\n",
      "Epoch: 575 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.278\n",
      "Epoch: 574 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.272\n",
      "Epoch: 573 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.271\n",
      "Epoch: 572 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.274\n",
      "Epoch: 571 | T_Loss 0.695 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.269\n",
      "Epoch: 570 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.267\n",
      "Epoch: 569 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.269\n",
      "Epoch: 568 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.265\n",
      "Epoch: 567 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.265\n",
      "Epoch: 566 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 |  1.26\n",
      "Epoch: 565 | T_Loss 0.696 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 |  1.26\n",
      "Epoch: 564 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.258\n",
      "Epoch: 563 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.257\n",
      "Epoch: 562 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.257\n",
      "Epoch: 561 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.253\n",
      "Epoch: 560 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.252\n",
      "Epoch: 559 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.251\n",
      "Epoch: 558 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.247\n",
      "Epoch: 557 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.245\n",
      "Epoch: 556 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.244\n",
      "Epoch: 555 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.243\n",
      "Epoch: 554 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.238\n",
      "Epoch: 553 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.238\n",
      "Epoch: 552 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.237\n",
      "Epoch: 551 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.236\n",
      "Epoch: 550 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.233\n",
      "Epoch: 549 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.231\n",
      "Epoch: 548 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.228\n",
      "Epoch: 547 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.223\n",
      "Epoch: 546 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.226\n",
      "Epoch: 545 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.225\n",
      "Epoch: 544 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.225\n",
      "Epoch: 543 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.222\n",
      "Epoch: 542 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.218\n",
      "Epoch: 541 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.214\n",
      "Epoch: 540 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.214\n",
      "Epoch: 539 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 1.213\n",
      "Epoch: 538 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.212\n",
      "Epoch: 537 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.209\n",
      "Epoch: 536 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 |  1.21\n",
      "Epoch: 535 | T_Loss 0.695 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.207\n",
      "Epoch: 534 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.206\n",
      "Epoch: 533 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 |   1.2\n",
      "Epoch: 532 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.201\n",
      "Epoch: 531 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.199\n",
      "Epoch: 530 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.194\n",
      "Epoch: 529 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.195\n",
      "Epoch: 528 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.188\n",
      "Epoch: 527 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.194\n",
      "Epoch: 526 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.189\n",
      "Epoch: 525 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.189\n",
      "Epoch: 524 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.187\n",
      "Epoch: 523 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.182\n",
      "Epoch: 522 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.181\n",
      "Epoch: 521 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.181\n",
      "Epoch: 520 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.178\n",
      "Epoch: 519 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 1.178\n",
      "Epoch: 518 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.177\n",
      "Epoch: 517 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.172\n",
      "Epoch: 516 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.169\n",
      "Epoch: 515 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.169\n",
      "Epoch: 514 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.169\n",
      "Epoch: 513 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.166\n",
      "Epoch: 512 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.162\n",
      "Epoch: 511 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.166\n",
      "Epoch: 510 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.161\n",
      "Epoch: 509 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |  1.16\n",
      "Epoch: 508 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.155\n",
      "Epoch: 507 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.155\n",
      "Epoch: 506 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.152\n",
      "Epoch: 505 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.152\n",
      "Epoch: 504 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |  1.15\n",
      "Epoch: 503 | T_Loss 0.686 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.148\n",
      "Epoch: 502 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.145\n",
      "Epoch: 501 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.147\n",
      "Epoch: 500 | T_Loss 0.686 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.144\n",
      "Epoch: 499 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 |  1.14\n",
      "Epoch: 498 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.141\n",
      "Epoch: 497 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.139\n",
      "Epoch: 496 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.132\n",
      "Epoch: 495 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.135\n",
      "Epoch: 494 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.132\n",
      "Epoch: 493 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.129\n",
      "Epoch: 492 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.129\n",
      "Epoch: 491 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.127\n",
      "Epoch: 490 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.124\n",
      "Epoch: 489 | T_Loss  0.69 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 |  1.12\n",
      "Epoch: 488 | T_Loss 0.691 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.118\n",
      "Epoch: 487 | T_Loss 0.692 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.119\n",
      "Epoch: 486 | T_Loss 0.688 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.118\n",
      "Epoch: 485 | T_Loss 0.688 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.116\n",
      "Epoch: 484 | T_Loss 0.688 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.114\n",
      "Epoch: 483 | T_Loss 0.691 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.111\n",
      "Epoch: 482 | T_Loss  0.69 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.112\n",
      "Epoch: 481 | T_Loss 0.688 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.107\n",
      "Epoch: 480 | T_Loss  0.69 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.106\n",
      "Epoch: 479 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.104\n",
      "Epoch: 478 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.104\n",
      "Epoch: 477 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.101\n",
      "Epoch: 476 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.102\n",
      "Epoch: 475 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.098\n",
      "Epoch: 474 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.099\n",
      "Epoch: 473 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.096\n",
      "Epoch: 472 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.094\n",
      "Epoch: 471 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.093\n",
      "Epoch: 470 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 |  1.09\n",
      "Epoch: 469 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.089\n",
      "Epoch: 468 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.086\n",
      "Epoch: 467 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.082\n",
      "Epoch: 466 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.084\n",
      "Epoch: 465 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.082\n",
      "Epoch: 464 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.078\n",
      "Epoch: 463 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.079\n",
      "Epoch: 462 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.075\n",
      "Epoch: 461 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.073\n",
      "Epoch: 460 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.069\n",
      "Epoch: 459 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |  1.07\n",
      "Epoch: 458 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.067\n",
      "Epoch: 457 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.066\n",
      "Epoch: 456 | T_Loss 0.694 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.064\n",
      "Epoch: 455 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.063\n",
      "Epoch: 454 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.063\n",
      "Epoch: 453 | T_Loss 0.694 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.061\n",
      "Epoch: 452 | T_Loss 0.689 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.056\n",
      "Epoch: 451 | T_Loss 0.689 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.059\n",
      "Epoch: 450 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 1.058\n",
      "Epoch: 449 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 1.054\n",
      "Epoch: 448 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 1.051\n",
      "Epoch: 447 | T_Loss 0.688 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.049\n",
      "Epoch: 446 | T_Loss 0.687 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 1.046\n",
      "Epoch: 445 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.047\n",
      "Epoch: 444 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.042\n",
      "Epoch: 443 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 |  1.04\n",
      "Epoch: 442 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.037\n",
      "Epoch: 441 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.036\n",
      "Epoch: 440 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.035\n",
      "Epoch: 439 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.035\n",
      "Epoch: 438 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |  1.03\n",
      "Epoch: 437 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.031\n",
      "Epoch: 436 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.026\n",
      "Epoch: 435 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.026\n",
      "Epoch: 434 | T_Loss 0.686 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.023\n",
      "Epoch: 433 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.025\n",
      "Epoch: 432 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.022\n",
      "Epoch: 431 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 |  1.02\n",
      "Epoch: 430 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.016\n",
      "Epoch: 429 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.018\n",
      "Epoch: 428 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 1.016\n",
      "Epoch: 427 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.011\n",
      "Epoch: 426 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 1.018\n",
      "Epoch: 425 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.009\n",
      "Epoch: 424 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.005\n",
      "Epoch: 423 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.007\n",
      "Epoch: 422 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 1.004\n",
      "Epoch: 421 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 1.001\n",
      "Epoch: 420 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 |   1.0\n",
      "Epoch: 419 | T_Loss 0.686 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.999\n",
      "Epoch: 418 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |   1.0\n",
      "Epoch: 417 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.993\n",
      "Epoch: 416 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.993\n",
      "Epoch: 415 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.992\n",
      "Epoch: 414 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.987\n",
      "Epoch: 413 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |  0.99\n",
      "Epoch: 412 | T_Loss 0.686 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.987\n",
      "Epoch: 411 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.985\n",
      "Epoch: 410 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.982\n",
      "Epoch: 409 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.979\n",
      "Epoch: 408 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.979\n",
      "Epoch: 407 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.979\n",
      "Epoch: 406 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.978\n",
      "Epoch: 405 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.977\n",
      "Epoch: 404 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.973\n",
      "Epoch: 403 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.971\n",
      "Epoch: 402 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.969\n",
      "Epoch: 401 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.967\n",
      "Epoch: 400 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.962\n",
      "Epoch: 399 | T_Loss 0.686 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 |  0.96\n",
      "Epoch: 398 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 0.961\n",
      "Epoch: 397 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 0.959\n",
      "Epoch: 396 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 0.956\n",
      "Epoch: 395 | T_Loss 0.695 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 0.958\n",
      "Epoch: 394 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 0.951\n",
      "Epoch: 393 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 |  0.95\n",
      "Epoch: 392 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.947\n",
      "Epoch: 391 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 |  0.95\n",
      "Epoch: 390 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.944\n",
      "Epoch: 389 | T_Loss 0.696 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.941\n",
      "Epoch: 388 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.942\n",
      "Epoch: 387 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |  0.94\n",
      "Epoch: 386 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.939\n",
      "Epoch: 385 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.935\n",
      "Epoch: 384 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.935\n",
      "Epoch: 383 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.931\n",
      "Epoch: 382 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.929\n",
      "Epoch: 381 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.928\n",
      "Epoch: 380 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.927\n",
      "Epoch: 379 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.923\n",
      "Epoch: 378 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.925\n",
      "Epoch: 377 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |  0.92\n",
      "Epoch: 376 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.917\n",
      "Epoch: 375 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.919\n",
      "Epoch: 374 | T_Loss 0.685 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.913\n",
      "Epoch: 373 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.911\n",
      "Epoch: 372 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.913\n",
      "Epoch: 371 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.908\n",
      "Epoch: 370 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.909\n",
      "Epoch: 369 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.904\n",
      "Epoch: 368 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.904\n",
      "Epoch: 367 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.902\n",
      "Epoch: 366 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |   0.9\n",
      "Epoch: 365 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.897\n",
      "Epoch: 364 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.898\n",
      "Epoch: 363 | T_Loss 0.685 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.892\n",
      "Epoch: 362 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.893\n",
      "Epoch: 361 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.892\n",
      "Epoch: 360 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.892\n",
      "Epoch: 359 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.888\n",
      "Epoch: 358 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.886\n",
      "Epoch: 357 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.883\n",
      "Epoch: 356 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.881\n",
      "Epoch: 355 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 |  0.88\n",
      "Epoch: 354 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.875\n",
      "Epoch: 353 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.874\n",
      "Epoch: 352 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.873\n",
      "Epoch: 351 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.871\n",
      "Epoch: 350 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.872\n",
      "Epoch: 349 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.868\n",
      "Epoch: 348 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.867\n",
      "Epoch: 347 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.864\n",
      "Epoch: 346 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.864\n",
      "Epoch: 345 | T_Loss 0.684 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.864\n",
      "Epoch: 344 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.859\n",
      "Epoch: 343 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.858\n",
      "Epoch: 342 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.857\n",
      "Epoch: 341 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.853\n",
      "Epoch: 340 | T_Loss  0.69 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 0.854\n",
      "Epoch: 339 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 |  0.85\n",
      "Epoch: 338 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.846\n",
      "Epoch: 337 | T_Loss 0.694 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.848\n",
      "Epoch: 336 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.608 | V_Acc   1.0 | 0.847\n",
      "Epoch: 335 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.608 | V_Acc   1.0 | 0.845\n",
      "Epoch: 334 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.608 | V_Acc   1.0 | 0.842\n",
      "Epoch: 333 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.608 | V_Acc   1.0 | 0.839\n",
      "Epoch: 332 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.608 | V_Acc   1.0 | 0.839\n",
      "Epoch: 331 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.608 | V_Acc   1.0 | 0.832\n",
      "Epoch: 330 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.608 | V_Acc   1.0 | 0.834\n",
      "Epoch: 329 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.608 | V_Acc   1.0 | 0.832\n",
      "Epoch: 328 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.828\n",
      "Epoch: 327 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.829\n",
      "Epoch: 326 | T_Loss 0.689 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 0.826\n",
      "Epoch: 325 | T_Loss 0.691 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 0.824\n",
      "Epoch: 324 | T_Loss 0.689 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 0.821\n",
      "Epoch: 323 | T_Loss 0.689 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 0.821\n",
      "Epoch: 322 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.817\n",
      "Epoch: 321 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.821\n",
      "Epoch: 320 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.817\n",
      "Epoch: 319 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.817\n",
      "Epoch: 318 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 |  0.81\n",
      "Epoch: 317 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.811\n",
      "Epoch: 316 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.809\n",
      "Epoch: 315 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.806\n",
      "Epoch: 314 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.805\n",
      "Epoch: 313 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.801\n",
      "Epoch: 312 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.799\n",
      "Epoch: 311 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.799\n",
      "Epoch: 310 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.797\n",
      "Epoch: 309 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.793\n",
      "Epoch: 308 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.794\n",
      "Epoch: 307 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.794\n",
      "Epoch: 306 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 |  0.79\n",
      "Epoch: 305 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.786\n",
      "Epoch: 304 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.788\n",
      "Epoch: 303 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.783\n",
      "Epoch: 302 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.784\n",
      "Epoch: 301 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.783\n",
      "Epoch: 300 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.777\n",
      "Epoch: 299 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |  0.78\n",
      "Epoch: 298 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.775\n",
      "Epoch: 297 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.774\n",
      "Epoch: 296 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.772\n",
      "Epoch: 295 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.771\n",
      "Epoch: 294 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.769\n",
      "Epoch: 293 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.767\n",
      "Epoch: 292 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.768\n",
      "Epoch: 291 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.761\n",
      "Epoch: 290 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.758\n",
      "Epoch: 289 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.757\n",
      "Epoch: 288 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.758\n",
      "Epoch: 287 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.756\n",
      "Epoch: 286 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.757\n",
      "Epoch: 285 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.751\n",
      "Epoch: 284 | T_Loss 0.685 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.752\n",
      "Epoch: 283 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.745\n",
      "Epoch: 282 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.746\n",
      "Epoch: 281 | T_Loss 0.694 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.745\n",
      "Epoch: 280 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.746\n",
      "Epoch: 279 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.742\n",
      "Epoch: 278 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.738\n",
      "Epoch: 277 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.738\n",
      "Epoch: 276 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.736\n",
      "Epoch: 275 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.735\n",
      "Epoch: 274 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.732\n",
      "Epoch: 273 | T_Loss 0.686 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 |  0.73\n",
      "Epoch: 272 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.728\n",
      "Epoch: 271 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 0.723\n",
      "Epoch: 270 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 0.725\n",
      "Epoch: 269 | T_Loss 0.686 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.723\n",
      "Epoch: 268 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.721\n",
      "Epoch: 267 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.719\n",
      "Epoch: 266 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.717\n",
      "Epoch: 265 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.715\n",
      "Epoch: 264 | T_Loss 0.691 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 0.711\n",
      "Epoch: 263 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.712\n",
      "Epoch: 262 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.608 | V_Acc   1.0 | 0.709\n",
      "Epoch: 261 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.608 | V_Acc   1.0 | 0.707\n",
      "Epoch: 260 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.608 | V_Acc   1.0 | 0.703\n",
      "Epoch: 259 | T_Loss 0.686 | T_Acc 0.542 | V_Loss 0.608 | V_Acc   1.0 | 0.704\n",
      "Epoch: 258 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.703\n",
      "Epoch: 257 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.701\n",
      "Epoch: 256 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.696\n",
      "Epoch: 255 | T_Loss 0.691 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 0.696\n",
      "Epoch: 254 | T_Loss 0.689 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 0.696\n",
      "Epoch: 253 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.695\n",
      "Epoch: 252 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.691\n",
      "Epoch: 251 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.693\n",
      "Epoch: 250 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.683\n",
      "Epoch: 249 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.685\n",
      "Epoch: 248 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.687\n",
      "Epoch: 247 | T_Loss 0.685 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.678\n",
      "Epoch: 246 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.681\n",
      "Epoch: 245 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.679\n",
      "Epoch: 244 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.669\n",
      "Epoch: 243 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.676\n",
      "Epoch: 242 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.677\n",
      "Epoch: 241 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.673\n",
      "Epoch: 240 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.669\n",
      "Epoch: 239 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.663\n",
      "Epoch: 238 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 |  0.67\n",
      "Epoch: 237 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.664\n",
      "Epoch: 236 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.661\n",
      "Epoch: 235 | T_Loss 0.686 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.661\n",
      "Epoch: 234 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 |  0.66\n",
      "Epoch: 233 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.657\n",
      "Epoch: 232 | T_Loss 0.684 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.656\n",
      "Epoch: 231 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.652\n",
      "Epoch: 230 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.653\n",
      "Epoch: 229 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.652\n",
      "Epoch: 228 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.651\n",
      "Epoch: 227 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.649\n",
      "Epoch: 226 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.643\n",
      "Epoch: 225 | T_Loss  0.69 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 0.643\n",
      "Epoch: 224 | T_Loss 0.696 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 0.641\n",
      "Epoch: 223 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 |  0.64\n",
      "Epoch: 222 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.633\n",
      "Epoch: 221 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.633\n",
      "Epoch: 220 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.635\n",
      "Epoch: 219 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.634\n",
      "Epoch: 218 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.629\n",
      "Epoch: 217 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.631\n",
      "Epoch: 216 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.609 | V_Acc   1.0 | 0.627\n",
      "Epoch: 215 | T_Loss 0.685 | T_Acc 0.542 | V_Loss  0.61 | V_Acc   1.0 | 0.625\n",
      "Epoch: 214 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.611 | V_Acc   1.0 | 0.621\n",
      "Epoch: 213 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.619\n",
      "Epoch: 212 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.612 | V_Acc   1.0 | 0.617\n",
      "Epoch: 211 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.613 | V_Acc   1.0 | 0.617\n",
      "Epoch: 210 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.617\n",
      "Epoch: 209 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 0.615\n",
      "Epoch: 208 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 0.609\n",
      "Epoch: 207 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.618 | V_Acc   1.0 | 0.613\n",
      "Epoch: 206 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.619 | V_Acc   1.0 | 0.605\n",
      "Epoch: 205 | T_Loss 0.689 | T_Acc 0.542 | V_Loss  0.62 | V_Acc   1.0 | 0.611\n",
      "Epoch: 204 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.622 | V_Acc   1.0 | 0.601\n",
      "Epoch: 203 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.625 | V_Acc   1.0 | 0.605\n",
      "Epoch: 202 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.628 | V_Acc   1.0 | 0.601\n",
      "Epoch: 201 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.631 | V_Acc   1.0 |   0.6\n",
      "Epoch: 200 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.634 | V_Acc   1.0 | 0.595\n",
      "Epoch: 199 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.637 | V_Acc   1.0 | 0.592\n",
      "Epoch: 198 | T_Loss 0.691 | T_Acc 0.542 | V_Loss  0.64 | V_Acc   1.0 |  0.59\n",
      "Epoch: 197 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.642 | V_Acc   1.0 |  0.59\n",
      "Epoch: 196 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.643 | V_Acc   1.0 | 0.591\n",
      "Epoch: 195 | T_Loss 0.695 | T_Acc 0.542 | V_Loss 0.644 | V_Acc   1.0 | 0.583\n",
      "Epoch: 194 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.642 | V_Acc   1.0 | 0.583\n",
      "Epoch: 193 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.637 | V_Acc   1.0 |  0.58\n",
      "Epoch: 192 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.626 | V_Acc   1.0 | 0.578\n",
      "Epoch: 191 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.607 | V_Acc   1.0 |  0.58\n",
      "Epoch: 190 | T_Loss 0.698 | T_Acc 0.542 | V_Loss 0.575 | V_Acc   1.0 |  0.58\n",
      "Epoch: 189 | T_Loss 0.714 | T_Acc 0.542 | V_Loss 0.518 | V_Acc   1.0 | 0.573\n",
      "Epoch: 188 | T_Loss 0.781 | T_Acc 0.542 | V_Loss  0.42 | V_Acc   1.0 | 0.571\n",
      "Epoch: 187 | T_Loss 0.952 | T_Acc 0.542 | V_Loss 0.271 | V_Acc   1.0 |  0.57\n",
      "Epoch: 186 | T_Loss 1.162 | T_Acc 0.542 | V_Loss 0.142 | V_Acc   1.0 | 0.571\n",
      "Epoch: 185 | T_Loss 1.375 | T_Acc 0.542 | V_Loss 0.078 | V_Acc   1.0 | 0.571\n",
      "Epoch: 184 | T_Loss 1.535 | T_Acc 0.542 | V_Loss 0.045 | V_Acc   1.0 | 0.565\n",
      "Epoch: 183 | T_Loss  1.62 | T_Acc 0.542 | V_Loss 0.034 | V_Acc   1.0 | 0.562\n",
      "Epoch: 182 | T_Loss 1.686 | T_Acc 0.542 | V_Loss 0.029 | V_Acc   1.0 | 0.559\n",
      "Epoch: 181 | T_Loss 1.733 | T_Acc 0.542 | V_Loss 0.025 | V_Acc   1.0 | 0.561\n",
      "Epoch: 180 | T_Loss 1.781 | T_Acc 0.542 | V_Loss 0.022 | V_Acc   1.0 | 0.558\n",
      "Epoch: 179 | T_Loss 1.855 | T_Acc   0.5 | V_Loss  0.02 | V_Acc   1.0 | 0.555\n",
      "Epoch: 178 | T_Loss 0.492 | T_Acc 0.708 | V_Loss 0.309 | V_Acc 0.667 | 0.552\n",
      "Epoch: 177 | T_Loss 0.502 | T_Acc 0.708 | V_Loss 0.878 | V_Acc   0.0 | 0.549\n",
      "Epoch: 176 | T_Loss 0.503 | T_Acc 0.708 | V_Loss 0.934 | V_Acc   0.0 | 0.549\n",
      "Epoch: 175 | T_Loss 0.505 | T_Acc 0.708 | V_Loss 0.937 | V_Acc   0.0 | 0.547\n",
      "Epoch: 174 | T_Loss 0.505 | T_Acc 0.708 | V_Loss 0.939 | V_Acc   0.0 | 0.545\n",
      "Epoch: 173 | T_Loss 0.506 | T_Acc 0.708 | V_Loss 0.939 | V_Acc   0.0 | 0.544\n",
      "Epoch: 172 | T_Loss 0.503 | T_Acc 0.708 | V_Loss 0.939 | V_Acc   0.0 | 0.539\n",
      "Epoch: 171 | T_Loss 0.503 | T_Acc 0.708 | V_Loss 0.939 | V_Acc   0.0 | 0.542\n",
      "Epoch: 170 | T_Loss 0.506 | T_Acc 0.708 | V_Loss 0.939 | V_Acc   0.0 | 0.536\n",
      "Epoch: 169 | T_Loss 0.505 | T_Acc 0.708 | V_Loss  0.94 | V_Acc   0.0 | 0.536\n",
      "Epoch: 168 | T_Loss 0.507 | T_Acc 0.708 | V_Loss  0.94 | V_Acc   0.0 | 0.532\n",
      "Epoch: 167 | T_Loss 0.507 | T_Acc 0.708 | V_Loss 0.941 | V_Acc   0.0 | 0.534\n",
      "Epoch: 166 | T_Loss 0.506 | T_Acc 0.708 | V_Loss 0.941 | V_Acc   0.0 | 0.526\n",
      "Epoch: 165 | T_Loss 0.506 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.527\n",
      "Epoch: 164 | T_Loss 0.506 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.525\n",
      "Epoch: 163 | T_Loss 0.505 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.524\n",
      "Epoch: 162 | T_Loss 0.505 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.522\n",
      "Epoch: 161 | T_Loss 0.507 | T_Acc 0.708 | V_Loss 0.943 | V_Acc   0.0 | 0.517\n",
      "Epoch: 160 | T_Loss 0.506 | T_Acc 0.708 | V_Loss 0.943 | V_Acc   0.0 |  0.52\n",
      "Epoch: 159 | T_Loss 0.506 | T_Acc 0.708 | V_Loss 0.943 | V_Acc   0.0 | 0.518\n",
      "Epoch: 158 | T_Loss 0.505 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.516\n",
      "Epoch: 157 | T_Loss 0.506 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 |  0.51\n",
      "Epoch: 156 | T_Loss 0.506 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.509\n",
      "Epoch: 155 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.508\n",
      "Epoch: 154 | T_Loss 0.507 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.507\n",
      "Epoch: 153 | T_Loss 0.505 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.502\n",
      "Epoch: 152 | T_Loss 0.507 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.503\n",
      "Epoch: 151 | T_Loss 0.506 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.499\n",
      "Epoch: 150 | T_Loss 0.505 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.497\n",
      "Epoch: 149 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.497\n",
      "Epoch: 148 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.943 | V_Acc   0.0 | 0.492\n",
      "Epoch: 147 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.943 | V_Acc   0.0 | 0.488\n",
      "Epoch: 146 | T_Loss 0.507 | T_Acc 0.708 | V_Loss 0.943 | V_Acc   0.0 |  0.49\n",
      "Epoch: 145 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.943 | V_Acc   0.0 | 0.486\n",
      "Epoch: 144 | T_Loss 0.506 | T_Acc 0.708 | V_Loss 0.943 | V_Acc   0.0 | 0.489\n",
      "Epoch: 143 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.475\n",
      "Epoch: 142 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.481\n",
      "Epoch: 141 | T_Loss  0.51 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.478\n",
      "Epoch: 140 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.945 | V_Acc   0.0 | 0.476\n",
      "Epoch: 139 | T_Loss 0.507 | T_Acc 0.708 | V_Loss 0.945 | V_Acc   0.0 | 0.474\n",
      "Epoch: 138 | T_Loss 0.506 | T_Acc 0.708 | V_Loss 0.945 | V_Acc   0.0 | 0.475\n",
      "Epoch: 137 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.473\n",
      "Epoch: 136 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.468\n",
      "Epoch: 135 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.469\n",
      "Epoch: 134 | T_Loss 0.507 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.466\n",
      "Epoch: 133 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.464\n",
      "Epoch: 132 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.462\n",
      "Epoch: 131 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.458\n",
      "Epoch: 130 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.458\n",
      "Epoch: 129 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.455\n",
      "Epoch: 128 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.944 | V_Acc   0.0 | 0.454\n",
      "Epoch: 127 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.943 | V_Acc   0.0 | 0.452\n",
      "Epoch: 126 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.943 | V_Acc   0.0 | 0.449\n",
      "Epoch: 125 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.943 | V_Acc   0.0 | 0.447\n",
      "Epoch: 124 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.446\n",
      "Epoch: 123 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.942 | V_Acc   0.0 | 0.444\n",
      "Epoch: 122 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.941 | V_Acc   0.0 | 0.441\n",
      "Epoch: 121 | T_Loss 0.508 | T_Acc 0.708 | V_Loss  0.94 | V_Acc   0.0 |  0.44\n",
      "Epoch: 120 | T_Loss 0.509 | T_Acc 0.708 | V_Loss  0.94 | V_Acc   0.0 | 0.437\n",
      "Epoch: 119 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.939 | V_Acc   0.0 | 0.435\n",
      "Epoch: 118 | T_Loss  0.51 | T_Acc 0.708 | V_Loss 0.938 | V_Acc   0.0 | 0.436\n",
      "Epoch: 117 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.937 | V_Acc   0.0 | 0.434\n",
      "Epoch: 116 | T_Loss 0.508 | T_Acc 0.708 | V_Loss 0.936 | V_Acc   0.0 | 0.429\n",
      "Epoch: 115 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.936 | V_Acc   0.0 | 0.428\n",
      "Epoch: 114 | T_Loss  0.51 | T_Acc 0.708 | V_Loss 0.935 | V_Acc   0.0 | 0.427\n",
      "Epoch: 113 | T_Loss 0.509 | T_Acc 0.708 | V_Loss 0.934 | V_Acc   0.0 | 0.425\n",
      "Epoch: 112 | T_Loss  0.51 | T_Acc 0.708 | V_Loss 0.933 | V_Acc   0.0 | 0.422\n",
      "Epoch: 111 | T_Loss 0.511 | T_Acc 0.708 | V_Loss 0.933 | V_Acc   0.0 | 0.424\n",
      "Epoch: 110 | T_Loss  0.51 | T_Acc 0.708 | V_Loss 0.932 | V_Acc   0.0 | 0.419\n",
      "Epoch: 109 | T_Loss  0.51 | T_Acc 0.708 | V_Loss 0.931 | V_Acc   0.0 | 0.417\n",
      "Epoch: 108 | T_Loss 0.511 | T_Acc 0.708 | V_Loss  0.93 | V_Acc   0.0 | 0.417\n",
      "Epoch: 107 | T_Loss 0.511 | T_Acc 0.708 | V_Loss 0.928 | V_Acc   0.0 | 0.414\n",
      "Epoch: 106 | T_Loss  0.51 | T_Acc 0.708 | V_Loss 0.927 | V_Acc   0.0 | 0.413\n",
      "Epoch: 105 | T_Loss  0.51 | T_Acc 0.708 | V_Loss 0.925 | V_Acc   0.0 | 0.406\n",
      "Epoch: 104 | T_Loss 0.511 | T_Acc 0.708 | V_Loss 0.923 | V_Acc   0.0 | 0.408\n",
      "Epoch: 103 | T_Loss 0.511 | T_Acc 0.708 | V_Loss 0.921 | V_Acc   0.0 | 0.398\n",
      "Epoch: 102 | T_Loss 0.512 | T_Acc 0.708 | V_Loss 0.919 | V_Acc   0.0 | 0.404\n",
      "Epoch: 101 | T_Loss 0.513 | T_Acc 0.708 | V_Loss 0.917 | V_Acc   0.0 | 0.402\n",
      "Epoch: 100 | T_Loss 0.512 | T_Acc 0.708 | V_Loss 0.915 | V_Acc   0.0 | 0.401\n",
      "Epoch:  99 | T_Loss 0.512 | T_Acc 0.708 | V_Loss 0.912 | V_Acc   0.0 | 0.399\n",
      "Epoch:  98 | T_Loss 0.512 | T_Acc 0.708 | V_Loss  0.91 | V_Acc   0.0 | 0.388\n",
      "Epoch:  97 | T_Loss 0.512 | T_Acc 0.708 | V_Loss 0.907 | V_Acc   0.0 | 0.392\n",
      "Epoch:  96 | T_Loss 0.513 | T_Acc 0.708 | V_Loss 0.904 | V_Acc   0.0 | 0.394\n",
      "Epoch:  95 | T_Loss 0.514 | T_Acc 0.708 | V_Loss   0.9 | V_Acc   0.0 | 0.393\n",
      "Epoch:  94 | T_Loss 0.514 | T_Acc 0.708 | V_Loss 0.897 | V_Acc   0.0 | 0.385\n",
      "Epoch:  93 | T_Loss 0.514 | T_Acc 0.708 | V_Loss 0.893 | V_Acc   0.0 | 0.384\n",
      "Epoch:  92 | T_Loss 0.515 | T_Acc 0.708 | V_Loss 0.889 | V_Acc   0.0 | 0.385\n",
      "Epoch:  91 | T_Loss 0.516 | T_Acc 0.708 | V_Loss 0.884 | V_Acc   0.0 | 0.384\n",
      "Epoch:  90 | T_Loss 0.517 | T_Acc 0.708 | V_Loss 0.879 | V_Acc   0.0 | 0.382\n",
      "Epoch:  89 | T_Loss 0.516 | T_Acc 0.708 | V_Loss 0.874 | V_Acc   0.0 | 0.372\n",
      "Epoch:  88 | T_Loss 0.516 | T_Acc 0.708 | V_Loss 0.868 | V_Acc   0.0 | 0.374\n",
      "Epoch:  87 | T_Loss 0.516 | T_Acc 0.708 | V_Loss 0.861 | V_Acc   0.0 | 0.376\n",
      "Epoch:  86 | T_Loss 0.518 | T_Acc 0.708 | V_Loss 0.855 | V_Acc   0.0 | 0.374\n",
      "Epoch:  85 | T_Loss 0.518 | T_Acc 0.708 | V_Loss 0.849 | V_Acc   0.0 | 0.372\n",
      "Epoch:  84 | T_Loss  0.52 | T_Acc 0.708 | V_Loss 0.842 | V_Acc   0.0 | 0.359\n",
      "Epoch:  83 | T_Loss 0.521 | T_Acc 0.708 | V_Loss 0.835 | V_Acc   0.0 | 0.356\n",
      "Epoch:  82 | T_Loss 0.523 | T_Acc 0.708 | V_Loss 0.829 | V_Acc   0.0 | 0.363\n",
      "Epoch:  81 | T_Loss 0.523 | T_Acc 0.708 | V_Loss 0.822 | V_Acc   0.0 | 0.361\n",
      "Epoch:  80 | T_Loss 0.526 | T_Acc 0.708 | V_Loss 0.815 | V_Acc   0.0 | 0.354\n",
      "Epoch:  79 | T_Loss 0.528 | T_Acc 0.708 | V_Loss 0.808 | V_Acc   0.0 | 0.357\n",
      "Epoch:  78 | T_Loss 0.528 | T_Acc 0.708 | V_Loss   0.8 | V_Acc   0.0 | 0.348\n",
      "Epoch:  77 | T_Loss 0.532 | T_Acc 0.708 | V_Loss 0.793 | V_Acc   0.0 | 0.344\n",
      "Epoch:  76 | T_Loss 0.534 | T_Acc 0.708 | V_Loss 0.785 | V_Acc   0.0 |  0.35\n",
      "Epoch:  75 | T_Loss 0.536 | T_Acc 0.708 | V_Loss 0.776 | V_Acc   0.0 | 0.349\n",
      "Epoch:  74 | T_Loss 0.539 | T_Acc 0.708 | V_Loss 0.768 | V_Acc   0.0 | 0.347\n",
      "Epoch:  73 | T_Loss 0.542 | T_Acc 0.708 | V_Loss 0.766 | V_Acc   0.0 |  0.34\n",
      "Epoch:  72 | T_Loss 0.545 | T_Acc 0.708 | V_Loss 0.763 | V_Acc   0.0 | 0.338\n",
      "Epoch:  71 | T_Loss 0.552 | T_Acc 0.667 | V_Loss 0.758 | V_Acc   0.0 | 0.332\n",
      "Epoch:  70 | T_Loss 0.573 | T_Acc 0.708 | V_Loss 0.744 | V_Acc   0.0 | 0.338\n",
      "Epoch:  69 | T_Loss 0.561 | T_Acc 0.667 | V_Loss 0.749 | V_Acc   0.0 | 0.331\n",
      "Epoch:  68 | T_Loss  0.58 | T_Acc 0.708 | V_Loss 0.739 | V_Acc   0.0 | 0.326\n",
      "Epoch:  67 | T_Loss 0.586 | T_Acc 0.708 | V_Loss 0.741 | V_Acc   0.0 | 0.324\n",
      "Epoch:  66 | T_Loss 0.604 | T_Acc 0.667 | V_Loss 0.738 | V_Acc   0.0 | 0.326\n",
      "Epoch:  65 | T_Loss 0.606 | T_Acc 0.667 | V_Loss 0.697 | V_Acc 0.333 |  0.32\n",
      "Epoch:  64 | T_Loss 0.599 | T_Acc 0.667 | V_Loss 0.697 | V_Acc 0.333 | 0.319\n",
      "Epoch:  63 | T_Loss 0.638 | T_Acc 0.625 | V_Loss 0.729 | V_Acc   0.0 | 0.319\n",
      "Epoch:  62 | T_Loss 0.634 | T_Acc 0.667 | V_Loss 0.729 | V_Acc   0.0 | 0.313\n",
      "Epoch:  61 | T_Loss 0.617 | T_Acc 0.458 | V_Loss 0.719 | V_Acc   0.0 | 0.315\n",
      "Epoch:  60 | T_Loss 0.631 | T_Acc 0.667 | V_Loss 0.661 | V_Acc 0.333 | 0.312\n",
      "Epoch:  59 | T_Loss 0.642 | T_Acc 0.708 | V_Loss 0.715 | V_Acc   0.0 | 0.308\n",
      "Epoch:  58 | T_Loss 0.644 | T_Acc   0.5 | V_Loss 0.708 | V_Acc   0.0 | 0.306\n",
      "Epoch:  57 | T_Loss 0.651 | T_Acc 0.542 | V_Loss 0.685 | V_Acc 0.333 | 0.307\n",
      "Epoch:  56 | T_Loss 0.659 | T_Acc 0.583 | V_Loss 0.677 | V_Acc 0.667 | 0.303\n",
      "Epoch:  55 | T_Loss 0.669 | T_Acc 0.542 | V_Loss 0.662 | V_Acc   1.0 |   0.3\n",
      "Epoch:  54 | T_Loss 0.676 | T_Acc 0.542 | V_Loss 0.644 | V_Acc   1.0 | 0.298\n",
      "Epoch:  53 | T_Loss 0.681 | T_Acc 0.542 | V_Loss 0.628 | V_Acc   1.0 | 0.295\n",
      "Epoch:  52 | T_Loss 0.684 | T_Acc 0.542 | V_Loss 0.621 | V_Acc   1.0 | 0.295\n",
      "Epoch:  51 | T_Loss 0.684 | T_Acc 0.542 | V_Loss 0.619 | V_Acc   1.0 | 0.291\n",
      "Epoch:  50 | T_Loss 0.686 | T_Acc 0.542 | V_Loss 0.618 | V_Acc   1.0 | 0.291\n",
      "Epoch:  49 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 |  0.29\n",
      "Epoch:  48 | T_Loss 0.687 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 0.286\n",
      "Epoch:  47 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.619 | V_Acc   1.0 | 0.284\n",
      "Epoch:  46 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.619 | V_Acc   1.0 | 0.284\n",
      "Epoch:  45 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.619 | V_Acc   1.0 |  0.28\n",
      "Epoch:  44 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.618 | V_Acc   1.0 | 0.279\n",
      "Epoch:  43 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.618 | V_Acc   1.0 | 0.278\n",
      "Epoch:  42 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.618 | V_Acc   1.0 | 0.274\n",
      "Epoch:  41 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.618 | V_Acc   1.0 | 0.272\n",
      "Epoch:  40 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 0.271\n",
      "Epoch:  39 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 0.268\n",
      "Epoch:  38 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 0.267\n",
      "Epoch:  37 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 0.265\n",
      "Epoch:  36 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 0.264\n",
      "Epoch:  35 | T_Loss 0.689 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 |  0.26\n",
      "Epoch:  34 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 0.259\n",
      "Epoch:  33 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.617 | V_Acc   1.0 | 0.256\n",
      "Epoch:  32 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 0.255\n",
      "Epoch:  31 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 0.253\n",
      "Epoch:  30 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.251\n",
      "Epoch:  29 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.249\n",
      "Epoch:  28 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.248\n",
      "Epoch:  27 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.245\n",
      "Epoch:  26 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.614 | V_Acc   1.0 | 0.243\n",
      "Epoch:  25 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.615 | V_Acc   1.0 | 0.241\n",
      "Epoch:  24 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.616 | V_Acc   1.0 | 0.239\n",
      "Epoch:  23 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.619 | V_Acc   1.0 | 0.238\n",
      "Epoch:  22 | T_Loss 0.688 | T_Acc 0.542 | V_Loss 0.624 | V_Acc   1.0 | 0.235\n",
      "Epoch:  21 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.632 | V_Acc   1.0 | 0.233\n",
      "Epoch:  20 | T_Loss  0.69 | T_Acc 0.542 | V_Loss 0.641 | V_Acc   1.0 | 0.232\n",
      "Epoch:  19 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.652 | V_Acc   1.0 |  0.23\n",
      "Epoch:  18 | T_Loss 0.691 | T_Acc 0.542 | V_Loss 0.663 | V_Acc   1.0 | 0.228\n",
      "Epoch:  17 | T_Loss 0.692 | T_Acc 0.542 | V_Loss 0.674 | V_Acc   1.0 | 0.226\n",
      "Epoch:  16 | T_Loss 0.693 | T_Acc 0.542 | V_Loss 0.683 | V_Acc   1.0 | 0.224\n",
      "Epoch:  15 | T_Loss 0.693 | T_Acc   0.5 | V_Loss  0.69 | V_Acc   1.0 | 0.223\n",
      "Epoch:  14 | T_Loss 0.694 | T_Acc 0.458 | V_Loss 0.697 | V_Acc   0.0 | 0.221\n",
      "Epoch:  13 | T_Loss 0.694 | T_Acc 0.458 | V_Loss 0.702 | V_Acc   0.0 | 0.218\n",
      "Epoch:  12 | T_Loss 0.695 | T_Acc 0.458 | V_Loss 0.707 | V_Acc   0.0 | 0.217\n",
      "Epoch:  11 | T_Loss 0.695 | T_Acc 0.458 | V_Loss 0.711 | V_Acc   0.0 | 0.216\n",
      "Epoch:  10 | T_Loss 0.695 | T_Acc 0.458 | V_Loss 0.715 | V_Acc   0.0 | 0.213\n",
      "Epoch:   9 | T_Loss 0.695 | T_Acc 0.458 | V_Loss 0.718 | V_Acc   0.0 | 0.212\n",
      "Epoch:   8 | T_Loss 0.696 | T_Acc 0.458 | V_Loss 0.722 | V_Acc   0.0 |  0.21\n",
      "Epoch:   7 | T_Loss 0.696 | T_Acc 0.458 | V_Loss 0.725 | V_Acc   0.0 | 0.208\n",
      "Epoch:   6 | T_Loss 0.697 | T_Acc 0.458 | V_Loss 0.728 | V_Acc   0.0 | 0.207\n",
      "Epoch:   5 | T_Loss 0.697 | T_Acc 0.458 | V_Loss 0.731 | V_Acc   0.0 | 0.205\n",
      "Epoch:   4 | T_Loss 0.698 | T_Acc 0.458 | V_Loss 0.734 | V_Acc   0.0 | 0.203\n",
      "Epoch:   3 | T_Loss 0.698 | T_Acc 0.458 | V_Loss 0.737 | V_Acc   0.0 | 0.201\n",
      "Epoch:   2 | T_Loss 0.698 | T_Acc 0.458 | V_Loss 0.739 | V_Acc   0.0 |   0.2\n",
      "Epoch:   1 | T_Loss 0.698 | T_Acc 0.458 | V_Loss 0.742 | V_Acc   0.0 | 0.316\n",
      "\n",
      " Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training initialization\n",
    "init_model()\n",
    "init_epoch()\n",
    "init_log()\n",
    "maximum_epoch = EPOCH\n",
    "\n",
    "# Training iteration\n",
    "\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "\n",
    "    tloss, tacc = epoch(train_loader, mode = 'train')\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = epoch(val_loader, mode = 'val')\n",
    "        record_valid_log(vloss, vacc)\n",
    "\n",
    "    print_log()\n",
    "\n",
    "print('\\n Training completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc.: 0.0\n",
      "Test Loss: 0.7791\n"
     ]
    }
   ],
   "source": [
    "# ì •í™•ë„ ê²€ì¦\n",
    "with torch.no_grad():\n",
    "    test_loss, test_acc = epoch(test_loader, mode = 'test')\n",
    "    test_acc = round(test_acc, 4)\n",
    "    test_loss = round(test_loss, 4)\n",
    "    print('Test Acc.: {}'.format(test_acc))\n",
    "    print('Test Loss: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1ë¶„ ì›ë³¸ ì˜ìƒìœ¼ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ì¥ëœ frameì˜ ê°œìˆ˜: 181\n"
     ]
    }
   ],
   "source": [
    "# ì˜ìƒ resize ë° ì¶”ì¶œ\n",
    "test_video_name = 'C_3_12_43_BU_SMC_10-14_12-17-14_CC_RGB_DF2_F2'\n",
    "#test_video_path = f'/content/drive/MyDrive/Colab_Notebooks/Anomaly Detection/{test_video_name}.mp4'\n",
    "test_video_path = f'/home/raccoon/jnwork/kimsungwook/zerobase_DL_project/source_code/model/{test_video_name}.mp4'\n",
    "cv2.destroyAllWindows()\n",
    "cap = cv2.VideoCapture(test_video_path)\n",
    "img_list = []\n",
    "\n",
    "if cap.isOpened():\n",
    "\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "            img = cv2.resize(img, (640, 640))\n",
    "            img_list.append(img)\n",
    "            # cv2_imshow(img)\n",
    "            # cv2.waitKey(1)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('ì €ì¥ëœ frameì˜ ê°œìˆ˜: {}'.format(len(img_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713501158.226075    3656 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1713501158.249397    6889 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.161.07), renderer: NVIDIA GeForce GTX 1080 Ti/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹œí€€ìŠ¤ ë°ì´í„° ë¶„ì„ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 181/181 [00:13<00:00, 13.84it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Yolov5 + Mediapipe Version\"\"\"\n",
    "\n",
    "net.eval()\n",
    "\n",
    "length = 30 # frame ìƒíƒœë¥¼ í‘œì‹œí•  ê¸¸ì´\n",
    "out_img_list = []\n",
    "dataset = []\n",
    "status = 'None'\n",
    "pose = mp_pose.Pose(static_image_mode=True, model_complexity=1, enable_segmentation=False, min_detection_confidence=n_CONFIDENCE)\n",
    "print('ì‹œí€€ìŠ¤ ë°ì´í„° ë¶„ì„ ì¤‘...')\n",
    "\n",
    "xy_list_list = []\n",
    "for img in tqdm(img_list):\n",
    "    res = yolo_model(img)\n",
    "    res_refine = res.pandas().xyxy[0].values\n",
    "\n",
    "    nms_human = len(res_refine)\n",
    "    if nms_human > 0:\n",
    "        for bbox in res_refine:\n",
    "            xx1, yy1, xx2, yy2 = int(bbox[0])-10, int(bbox[1]), int(bbox[2])+10, int(bbox[3])\n",
    "            if xx1 < 0:\n",
    "                xx1 = 0\n",
    "            elif xx2 > 639:\n",
    "                xx2 = 639\n",
    "            if yy1 < 0:\n",
    "                yy1 = 0\n",
    "            elif yy2 > 639:\n",
    "                yy2 = 639\n",
    "\n",
    "            start_point = (xx1, yy1)\n",
    "            end_point = (xx2, yy2)\n",
    "            if bbox[4] > y_CONFIDENCE:\n",
    "                img = cv2.rectangle(img, start_point, end_point, (0, 0, 255), 2)\n",
    "\n",
    "                c_img = img[yy1:yy2, xx1:xx2]\n",
    "                results = pose.process(cv2.cvtColor(c_img, cv2.COLOR_BGR2RGB)) # Yolo ë°”ìš´ë”© box ì•ˆì—ì„œ landmark dot ì¶”ì¶œ\n",
    "                if not results.pose_landmarks: continue\n",
    "                xy_list = []\n",
    "                idx = 0\n",
    "                draw_line_dic = {}\n",
    "                for x_and_y in results.pose_landmarks.landmark:\n",
    "                    if idx in attention_dot:\n",
    "                        xy_list.append(x_and_y.x)\n",
    "                        xy_list.append(x_and_y.y)\n",
    "                        x, y = int(x_and_y.x*(xx2-xx1)), int(x_and_y.y*(yy2-yy1))\n",
    "                        draw_line_dic[idx] = [x, y]\n",
    "                    idx += 1\n",
    "\n",
    "                xy_list_list.append(xy_list)\n",
    "                for line in draw_line:\n",
    "                    x1, y1 = draw_line_dic[line[0]][0], draw_line_dic[line[0]][1]\n",
    "                    x2, y2 = draw_line_dic[line[1]][0], draw_line_dic[line[1]][1]\n",
    "                    c_img = cv2.line(c_img, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "                if len(xy_list_list) == length:\n",
    "                    dataset = []\n",
    "                    dataset.append({'key' : 0, 'value' : xy_list_list})\n",
    "                    dataset = MyDataset(dataset)\n",
    "                    dataset = DataLoader(dataset)\n",
    "                    xy_list_list = []\n",
    "\n",
    "                    for data, label in dataset:\n",
    "                        data = data.to(device)\n",
    "                        with torch.no_grad():\n",
    "                            result = net(data)\n",
    "                            _, out = torch.max(result, 1)\n",
    "                            if out.item() == 0: status = 'Normal'\n",
    "                            else: status = 'Theft'\n",
    "\n",
    "    cv2.putText(img, status, (0, 50), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 0, 255), 2)\n",
    "    out_img_list.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì›ë³¸ ì˜ìƒ ë‚´ë³´ë‚´ê¸°\n",
    "filename = './output.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "fps = 3\n",
    "frameSize = (640, 640)\n",
    "isColor = True\n",
    "out = cv2.VideoWriter(filename, fourcc, fps, frameSize, isColor)\n",
    "for out_img in out_img_list:\n",
    "    out.write(out_img)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ëª¨ë¸ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì €ì¥í•˜ê¸°\n",
    "PATH = './'\n",
    "model_name = 'LSTM.pt'\n",
    "torch.save(net.state_dict(), PATH + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ì¥ëœ frameì˜ ê°œìˆ˜: 1483\n"
     ]
    }
   ],
   "source": [
    "# ì˜ìƒ resize ë° ì¶”ì¶œ\n",
    "test_video_name = 'sample_1.mov'\n",
    "#test_video_path = f'/content/drive/MyDrive/Colab_Notebooks/Anomaly Detection/{test_video_name}'\n",
    "test_video_path = f'/home/raccoon/jnwork/kimsungwook/zerobase_DL_project/source_code/model/{test_video_name}'\n",
    "cv2.destroyAllWindows()\n",
    "cap = cv2.VideoCapture(test_video_path)\n",
    "img_list = []\n",
    "\n",
    "if cap.isOpened():\n",
    "\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "            img = cv2.resize(img, (640, 640))\n",
    "            img_list.append(img)\n",
    "            # cv2_imshow(img)\n",
    "            # cv2.waitKey(1)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('ì €ì¥ëœ frameì˜ ê°œìˆ˜: {}'.format(len(img_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1713506886.337675    3656 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1713506886.362469   11895 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 535.161.07), renderer: NVIDIA GeForce GTX 1080 Ti/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹œí€€ìŠ¤ ë°ì´í„° ë¶„ì„ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1483/1483 [01:31<00:00, 16.28it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Yolov5 + Mediapipe Version\"\"\"\n",
    "\n",
    "net.eval()\n",
    "\n",
    "length = 30 # frame ìƒíƒœë¥¼ í‘œì‹œí•  ê¸¸ì´\n",
    "out_img_list = []\n",
    "dataset = []\n",
    "status = 'None'\n",
    "pose = mp_pose.Pose(static_image_mode=True, model_complexity=1, enable_segmentation=False, min_detection_confidence=n_CONFIDENCE)\n",
    "print('ì‹œí€€ìŠ¤ ë°ì´í„° ë¶„ì„ ì¤‘...')\n",
    "\n",
    "xy_list_list = []\n",
    "for img in tqdm(img_list):\n",
    "    res = yolo_model(img)\n",
    "    res_refine = res.pandas().xyxy[0].values\n",
    "\n",
    "    nms_human = len(res_refine)\n",
    "    if nms_human > 0:\n",
    "        for bbox in res_refine:\n",
    "            xx1, yy1, xx2, yy2 = int(bbox[0])-10, int(bbox[1]), int(bbox[2])+10, int(bbox[3])\n",
    "            if xx1 < 0:\n",
    "                xx1 = 0\n",
    "            elif xx2 > 639:\n",
    "                xx2 = 639\n",
    "            if yy1 < 0:\n",
    "                yy1 = 0\n",
    "            elif yy2 > 639:\n",
    "                yy2 = 639\n",
    "\n",
    "            start_point = (xx1, yy1)\n",
    "            end_point = (xx2, yy2)\n",
    "            if bbox[4] > y_CONFIDENCE:\n",
    "                img = cv2.rectangle(img, start_point, end_point, (0, 0, 255), 2)\n",
    "\n",
    "                c_img = img[yy1:yy2, xx1:xx2]\n",
    "                results = pose.process(cv2.cvtColor(c_img, cv2.COLOR_BGR2RGB)) # Yolo ë°”ìš´ë”© box ì•ˆì—ì„œ landmark dot ì¶”ì¶œ\n",
    "                if not results.pose_landmarks: continue\n",
    "                xy_list = []\n",
    "                idx = 0\n",
    "                draw_line_dic = {}\n",
    "                for x_and_y in results.pose_landmarks.landmark:\n",
    "                    if idx in attention_dot:\n",
    "                        xy_list.append(x_and_y.x)\n",
    "                        xy_list.append(x_and_y.y)\n",
    "                        x, y = int(x_and_y.x*(xx2-xx1)), int(x_and_y.y*(yy2-yy1))\n",
    "                        draw_line_dic[idx] = [x, y]\n",
    "                    idx += 1\n",
    "\n",
    "                xy_list_list.append(xy_list)\n",
    "                for line in draw_line:\n",
    "                    x1, y1 = draw_line_dic[line[0]][0], draw_line_dic[line[0]][1]\n",
    "                    x2, y2 = draw_line_dic[line[1]][0], draw_line_dic[line[1]][1]\n",
    "                    c_img = cv2.line(c_img, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "\n",
    "                if len(xy_list_list) == length:\n",
    "                    dataset = []\n",
    "                    dataset.append({'key' : 0, 'value' : xy_list_list})\n",
    "                    dataset = MyDataset(dataset)\n",
    "                    dataset = DataLoader(dataset)\n",
    "                    xy_list_list = []\n",
    "\n",
    "                    for data, label in dataset:\n",
    "                        data = data.to(device)\n",
    "                        with torch.no_grad():\n",
    "                            result = net(data)\n",
    "                            _, out = torch.max(result, 1)\n",
    "                            if out.item() == 0: status = 'Normal'\n",
    "                            else: status = 'Theft'\n",
    "\n",
    "    cv2.putText(img, status, (0, 50), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 0, 255), 2)\n",
    "    out_img_list.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x58564944/'DIVX' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì›ë³¸ ì˜ìƒ ë‚´ë³´ë‚´ê¸°\n",
    "filename = './output2.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "fps = 3\n",
    "frameSize = (640, 640)\n",
    "isColor = True\n",
    "out = cv2.VideoWriter(filename, fourcc, fps, frameSize, isColor)\n",
    "for out_img in out_img_list:\n",
    "    out.write(out_img)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
